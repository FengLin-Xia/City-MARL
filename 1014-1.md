一步到位的修复清单（按优先级）
1) 采样端：把关键字段**序列化为“普通 CPU 标量/列表”**写入经验

CUDA/Tensor/ndarray 在跨进程/保存时最容易出事，干脆都存成基本类型。

# 采样时
selected_idx_int = int(selected_idx)
num_actions_int  = int(num_actions)
subset_indices_list = [int(x) for x in subset_indices.detach().cpu().tolist()]
old_log_prob_float = float(old_log_prob.detach().cpu().item())

experience.update({
    'action_index': selected_idx_int,
    'num_actions': num_actions_int,
    'subset_indices': subset_indices_list,
    'old_log_prob': old_log_prob_float,
    # 强烈建议：state_embed 也存 CPU 版，别存 GPU Tensor
    'state_embed': state_embed.detach().cpu().numpy(),  # 或 .cpu().tolist()
})


这样做可以避免后面 exp.get('subset_indices') 拿到的是 list 而你去 .numel() 报错/判无效的问题。

2) 训练端：不要再从 sequence 读 action_index，统一从 exp 读

你贴的训练段里有：

sequence = exp['action']
action_idx = getattr(sequence, 'action_index', -1)  # ← 这个一定要删


改成：

action_idx = int(exp.get('action_index', -1))
subset_ids = exp.get('subset_indices', None)
num_actions = exp.get('num_actions', None)
old_logp = exp.get('old_log_prob', None)

# 统一把它们转成张量
if subset_ids is not None:
    subset_ids = torch.as_tensor(subset_ids, device=self.device, dtype=torch.long)
if old_logp is not None:
    old_logp = torch.tensor([old_logp], device=self.device, dtype=torch.float32)

3) 重建局部分布时支持“list 索引”

之前用了 subset_ids.numel() 判断，这在 list 上会直接失败。改成通用版：

if subset_ids is None or num_actions is None or action_idx < 0:
    is_valid = False
else:
    # 支持 list/tensor 两种
    k = len(subset_ids) if not torch.is_tensor(subset_ids) else subset_ids.numel()
    is_valid = (0 <= action_idx < k)

if not is_valid:
    mark_invalid()
else:
    if torch.is_tensor(subset_ids):
        local_logits = logits[0, subset_ids]
    else:
        local_logits = logits[0, subset_ids]  # list[int] 也支持索引
    dist = torch.distributions.Categorical(logits=local_logits)
    new_logp = dist.log_prob(torch.tensor(action_idx, device=self.device))

4) 有效样本筛选逻辑前移，并避免空 batch 求均值

现在你是先拼全量张量再筛；若最后 0 条，后续 .mean() 会 NaN。直接在拼 batch 前过滤：

valid_exps = []
for exp in experiences:
    if is_valid_exp(exp):   # 按上面规则判断四件套是否齐全且索引合法
        valid_exps.append(exp)

if len(valid_exps) == 0:
    print("[skip] valid_ratio=0.00, no-op this update")
    continue  # 别再往下算任何 loss/metric

# 下面基于 valid_exps 构建 new_logp/old_logp/adv/ret/obs，再算 loss

5) 防止优势归一化把空张量/常数张量归出 NaN
if adv.numel() == 0:
    continue
std = adv.std(unbiased=False)
if torch.isnan(std) or std < 1e-8:
    std = torch.tensor(1.0, device=adv.device)
adv = (adv - adv.mean()) / std

6) 临时“救火兜底”（定位期）

在训练头部打一段逐字段的计数，立刻知道“0/30”怎么来的：

cnt = {"no_action_index":0, "no_subset":0, "no_num_actions":0, "no_old_logp":0, "oob_action_idx":0, "len_mismatch":0}
for exp in experiences:
    ai = exp.get('action_index', None)
    sid = exp.get('subset_indices', None)
    k   = exp.get('num_actions', None)
    olp = exp.get('old_log_prob', None)

    if ai is None: cnt["no_action_index"]+=1; continue
    if sid is None: cnt["no_subset"]+=1; continue
    if k is None: cnt["no_num_actions"]+=1; continue
    if olp is None: cnt["no_old_logp"]+=1; continue

    kk = len(sid) if not torch.is_tensor(sid) else sid.numel()
    if kk != k: cnt["len_mismatch"]+=1
    if not (0 <= int(ai) < kk): cnt["oob_action_idx"]+=1

print("[validity]", cnt)


如果你马上看到比如 no_subset:30 或 len_mismatch:30，就说明采样端那 4 个字段根本没进来/类型不对。