# åŸå¸‚æ¨¡æ‹Ÿç³»ç»Ÿè®¡ç®—é€»è¾‘å®Œæ•´è¯´æ˜

## ğŸ“‹ ç›®å½•
1. [ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ](#ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ)
2. [æ ¸å¿ƒè®¡ç®—æ¨¡å—](#æ ¸å¿ƒè®¡ç®—æ¨¡å—)
3. [Costè®¡ç®—è¯¦è§£](#costè®¡ç®—è¯¦è§£)
4. [Rewardè®¡ç®—è¯¦è§£](#rewardè®¡ç®—è¯¦è§£)
5. [Prestigeè®¡ç®—è¯¦è§£](#prestigeè®¡ç®—è¯¦è§£)
6. [RLå¥–åŠ±è®¡ç®—æœºåˆ¶](#rlå¥–åŠ±è®¡ç®—æœºåˆ¶)
7. [Budgetç³»ç»Ÿ](#budgetç³»ç»Ÿ)
8. [åŠ¨ä½œé€‰æ‹©ä¸è¯„åˆ†](#åŠ¨ä½œé€‰æ‹©ä¸è¯„åˆ†)
9. [é…ç½®å‚æ•°è¯¦è§£](#é…ç½®å‚æ•°è¯¦è§£)
10. [è®¡ç®—æµç¨‹ç¤ºä¾‹](#è®¡ç®—æµç¨‹ç¤ºä¾‹)

---

## ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ

### åŒå±‚è®¾è®¡æ¶æ„
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ActionScorer                          â”‚
â”‚  è®¡ç®—åŸå§‹ç»æµæŒ‡æ ‡ (cost/reward/prestige/score)           â”‚
â”‚  ä½ç½®: logic/v4_enumeration.py                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CityEnvironment                       â”‚
â”‚  åŸºäºactionå±æ€§ â†’ è®¡ç®—RLçš„total_reward                   â”‚
â”‚  ä½ç½®: envs/v4_1/city_env.py                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ä¸»è¦ç»„ä»¶
- **ActionScorer**: è®¡ç®—æ¯ä¸ªå»ºç­‘åŠ¨ä½œçš„ç»æµæŒ‡æ ‡
- **CityEnvironment**: å°†ç»æµæŒ‡æ ‡è½¬æ¢ä¸ºRLè®­ç»ƒå¥–åŠ±
- **Budgetç³»ç»Ÿ**: ç®¡ç†æ™ºèƒ½ä½“çš„è´¢åŠ¡çº¦æŸ
- **åœ°ä»·ç³»ç»Ÿ**: æä¾›åœ°ä»·ä¿¡æ¯ç”¨äºæˆæœ¬è®¡ç®—
- **æ²³æµç³»ç»Ÿ**: æä¾›æ²³æµæº¢ä»·å¥–åŠ±

---

## æ ¸å¿ƒè®¡ç®—æ¨¡å—

### 1. ActionScorer (`logic/v4_enumeration.py`)

**ä¸»è¦åŠŸèƒ½**:
- è®¡ç®—æ¯ä¸ªå»ºç­‘åŠ¨ä½œçš„costã€rewardã€prestige
- å½’ä¸€åŒ–å„ç»´åº¦æ•°å€¼
- è®¡ç®—ç»¼åˆè¯„åˆ†ç”¨äºåŠ¨ä½œæ’åº

**æ ¸å¿ƒæ–¹æ³•**:
```python
def _calc_crp(self, action, river_distance_provider=None, buildings=None):
    """è®¡ç®—cost/reward/prestige"""
    
def score_actions(self, actions, river_distance_provider=None, buildings=None):
    """å½’ä¸€åŒ–å¹¶è®¡ç®—ç»¼åˆè¯„åˆ†"""
```

### 2. CityEnvironment (`envs/v4_1/city_env.py`)

**ä¸»è¦åŠŸèƒ½**:
- å°†ActionScorerçš„ç»“æœè½¬æ¢ä¸ºRLå¥–åŠ±
- ç®¡ç†Budgetç³»ç»Ÿ
- å¤„ç†æœˆåº¦æ”¶ç›Šç´¯ç§¯
- è®¡ç®—åä½œå¥–åŠ±

**æ ¸å¿ƒæ–¹æ³•**:
```python
def _calculate_reward(self, agent, action):
    """è®¡ç®—RLè®­ç»ƒå¥–åŠ±"""
    
def _calculate_monthly_income(self, agent):
    """è®¡ç®—æœˆåº¦æ”¶ç›Šç´¯ç§¯"""
```

---

## Costè®¡ç®—è¯¦è§£

### åŸºç¡€å…¬å¼

**INDå»ºç­‘**:
```
cost = BaseCost_IND[size] + ZC[zone] + LP_value
```

**EDUå»ºç­‘**:
```
cost = BaseCost_EDU[size] + ZC[zone] + LP_value
```

### å‚æ•°è¯¦è§£

#### åŸºç¡€å»ºé€ æˆæœ¬
```json
BaseCost_IND = {
    "S": 900,   // å°å‹å·¥ä¸šå»ºç­‘
    "M": 1500,  // ä¸­å‹å·¥ä¸šå»ºç­‘  
    "L": 2400   // å¤§å‹å·¥ä¸šå»ºç­‘
}

BaseCost_EDU = {
    "S": 700,   // å°å‹æ•™è‚²å»ºç­‘
    "M": 1200,  // ä¸­å‹æ•™è‚²å»ºç­‘
    "L": 1900   // å¤§å‹æ•™è‚²å»ºç­‘
}
```

#### åŒºä½é™„åŠ æˆæœ¬
```json
ZC = {
    "near": 200,  // é è¿‘æ¢çº½åŒºåŸŸ
    "mid": 100,   // ä¸­ç­‰è·ç¦»åŒºåŸŸ
    "far": 0      // è¿œç¦»æ¢çº½åŒºåŸŸ
}
```

#### åœ°ä»·æˆæœ¬
```
LP_value = LP_idx Ã— LandPriceBase

å…¶ä¸­:
- LP_idx = 10~100 (åŸºäºLP_normçº¿æ€§æ˜ å°„)
- LandPriceBase = 11.0 kGBP/ç‚¹
- LP_valueèŒƒå›´: 110~1100 kGBP
```

### æˆæœ¬èŒƒå›´ç¤ºä¾‹

| å»ºç­‘ç±»å‹ | Size | åŸºç¡€æˆæœ¬ | åŒºä½å½±å“ | åœ°ä»·å½±å“ | æ€»æˆæœ¬èŒƒå›´ |
|---------|------|---------|---------|---------|-----------|
| IND | S | 900 | +0~200 | +110~1100 | **1010~2200 kGBP** |
| IND | M | 1500 | +0~200 | +110~1100 | **1610~2800 kGBP** |
| IND | L | 2400 | +0~200 | +110~1100 | **2510~3700 kGBP** |
| EDU | S | 700 | +0~200 | +110~1100 | **810~2000 kGBP** |
| EDU | M | 1200 | +0~200 | +110~1100 | **1310~2500 kGBP** |
| EDU | L | 1900 | +0~200 | +110~1100 | **2010~3200 kGBP** |

---

## Rewardè®¡ç®—è¯¦è§£

### åŸºç¡€å…¬å¼

**INDå»ºç­‘**:
```
reward_base = RevBase_IND[size] + ZR[zone] + Adj_bonus*adj - OPEX_IND[size] - Rent[size] + river_premium
reward = reward_base * (1 + RewardLP_k * LP_norm)
```

**EDUå»ºç­‘**:
```
reward_base = RevBase_EDU[size] + ZR[zone] + Adj_bonus*adj - OPEX_EDU[size] + river_premium
reward_land = Rent[size]
reward = reward_base + reward_land
```

### å‚æ•°è¯¦è§£

#### åŸºç¡€æœˆæ”¶å…¥
```json
RevBase_IND = {
    "S": 180,   // å°å‹å·¥ä¸šæœˆæ”¶å…¥
    "M": 320,   // ä¸­å‹å·¥ä¸šæœˆæ”¶å…¥
    "L": 520    // å¤§å‹å·¥ä¸šæœˆæ”¶å…¥
}

RevBase_EDU = {
    "S": 140,   // å°å‹æ•™è‚²æœˆæ”¶å…¥
    "M": 260,   // ä¸­å‹æ•™è‚²æœˆæ”¶å…¥
    "L": 420    // å¤§å‹æ•™è‚²æœˆæ”¶å…¥
}
```

#### åŒºä½æ”¶å…¥åŠ æˆ
```json
ZR = {
    "near": 80,  // é è¿‘æ¢çº½åŒºåŸŸ
    "mid": 40,   // ä¸­ç­‰è·ç¦»åŒºåŸŸ
    "far": 0     // è¿œç¦»æ¢çº½åŒºåŸŸ
}
```

#### è¿è¥æˆæœ¬
```json
OPEX_IND = {
    "S": 100,   // å°å‹å·¥ä¸šè¿è¥æˆæœ¬
    "M": 180,   // ä¸­å‹å·¥ä¸šè¿è¥æˆæœ¬
    "L": 300    // å¤§å‹å·¥ä¸šè¿è¥æˆæœ¬
}

OPEX_EDU = {
    "S": 70,    // å°å‹æ•™è‚²è¿è¥æˆæœ¬
    "M": 120,   // ä¸­å‹æ•™è‚²è¿è¥æˆæœ¬
    "L": 190    // å¤§å‹æ•™è‚²è¿è¥æˆæœ¬
}
```

#### ç§Ÿé‡‘æœºåˆ¶
```json
Rent = {
    "S": 25,    // å°å‹å»ºç­‘ç§Ÿé‡‘
    "M": 45,    // ä¸­å‹å»ºç­‘ç§Ÿé‡‘
    "L": 70     // å¤§å‹å»ºç­‘ç§Ÿé‡‘
}
```

**ç§Ÿé‡‘é€»è¾‘**:
- INDå»ºç­‘: æ”¯ä»˜ç§Ÿé‡‘ (reward -= Rent[size])
- EDUå»ºç­‘: è·å¾—ç§Ÿé‡‘ (reward += Rent[size])

#### åœ°ä»·å¢ç›Šç³»æ•°
```json
RewardLP_k = {
    "IND": 0.25,  // å·¥ä¸šå»ºç­‘åœ°ä»·å¢ç›Š
    "EDU": 0.10   // æ•™è‚²å»ºç­‘åœ°ä»·å¢ç›Š
}
```

### æ²³æµæº¢ä»·æœºåˆ¶

```
decay = 2^(-d_eff / RiverD_half_m)
BaseForPremium = RevBase_type[size] + ZR[zone]
RawRiverPrem = BaseForPremium Ã— RiverPmax_pct[type]/100 Ã— decay
RiverPremium = clamp(round_nearest(RawRiverPrem), 0, RiverPremiumCap)
```

**å‚æ•°**:
- `RiverPmax_pct`: IND=20%, EDU=15%
- `RiverD_half_m`: 120ç±³ (åŠè¡°è·ç¦»)
- `RiverPremiumCap`: 10000 kGBP (å°é¡¶å€¼)

### é‚»è¿‘æ€§å¥–åŠ±/æƒ©ç½š

**é‚»è¿‘å¥–åŠ±** (è·ç¦» â‰¤ 10å•ä½):
```
proximity_bonus = proximity_reward_val Ã— (1.0 - min_dist / proximity_threshold)
```

**è·ç¦»æƒ©ç½š** (è·ç¦» > 10å•ä½):
```
distance_penalty = (min_dist - proximity_threshold) Ã— distance_penalty_coef
```

**å‚æ•°**:
- `proximity_threshold`: 10.0
- `proximity_reward_val`: 50.0
- `distance_penalty_coef`: 2.0

### è§„æ¨¡å¥–åŠ± (Size Bonus)

```json
size_bonus = {
    "M": 1000,  // ä¸­å‹å»ºç­‘å¥–åŠ±
    "L": 2000   // å¤§å‹å»ºç­‘å¥–åŠ±
}
```

### æ”¶ç›Šè®¡ç®—ç¤ºä¾‹

**IND Må‹å»ºç­‘** (zone=near, LP_norm=0.8, è·ç¦»æ²³æµ30ç±³):
```
reward_base = 320 + 80 + 0 - 180 - 45 + 61 = 236
reward = 236 Ã— (1 + 0.25 Ã— 0.8) = 236 Ã— 1.2 = 283 kGBP/æœˆ
```

**EDU Lå‹å»ºç­‘** (zone=near, LP_norm=0.8, è·ç¦»æ²³æµ50ç±³):
```
reward_base = 420 + 80 + 0 - 190 + 45 = 355
reward_land = 70
reward = 355 + 70 = 425 kGBP/æœˆ
```

---

## Prestigeè®¡ç®—è¯¦è§£

### åŸºç¡€å…¬å¼

**EDUå»ºç­‘**:
```
prestige = PrestigeBase[size] + I(zone==near) + I(adj) - Î²Ã—Pollution[size]
```

**INDå»ºç­‘**:
```
prestige = PrestigeBase[size] + I(zone==near) + I(adj) - 0.2Ã—Pollution[size]
```

### å‚æ•°è¯¦è§£

#### åŸºç¡€å£°æœ›å€¼
```json
PrestigeBase_EDU = {
    "S": 0.2,   // å°å‹æ•™è‚²å£°æœ›
    "M": 0.6,   // ä¸­å‹æ•™è‚²å£°æœ›
    "L": 1.0    // å¤§å‹æ•™è‚²å£°æœ›
}

PrestigeBase_IND = {
    "S": 0.2,   // å°å‹å·¥ä¸šå£°æœ›
    "M": 0.1,   // ä¸­å‹å·¥ä¸šå£°æœ›
    "L": -0.1   // å¤§å‹å·¥ä¸šå£°æœ›(è´Ÿå€¼)
}
```

#### åŒºä½å’Œé‚»æ¥åŠ æˆ
- `I(zone==near)`: é è¿‘æ¢çº½åŒºåŸŸæ—¶ +1.0
- `I(adj)`: æœ‰é‚»æ¥å»ºç­‘æ—¶ +1.0

#### æ±¡æŸ“æƒ©ç½š
```json
Pollution_EDU = {
    "S": 0.2,
    "M": 0.4,
    "L": 0.6
}

Pollution_IND = {
    "S": 0.6,
    "M": 0.9,
    "L": 1.2
}
```

### Prestigeè®¡ç®—ç¤ºä¾‹

**EDU Lå‹å»ºç­‘** (nearåŒºåŸŸ, æœ‰é‚»æ¥, Î²=0.25):
```
prestige = 1.0 + 1.0 + 1.0 - 0.25Ã—0.6 = 2.85
```

**IND Lå‹å»ºç­‘** (midåŒºåŸŸ, æ— é‚»æ¥):
```
prestige = -0.1 + 0 + 0 - 0.2Ã—1.2 = -0.34
```

---

## RLå¥–åŠ±è®¡ç®—æœºåˆ¶

### è®¡ç®—æµç¨‹ (`envs/v4_1/city_env.py`)

```python
def _calculate_reward(self, agent, action):
    """è®¡ç®—å¥–åŠ±ï¼ˆå›ºå®šNPVæœºåˆ¶ï¼‰"""
    # 1. è®¡ç®—å»ºé€ æˆæœ¬
    build_cost = float(action.cost) if action.cost is not None else 0.0
    
    if build_cost > 0:  # æœ‰å»ºé€ 
        # 2. è®¡ç®—æœªæ¥æ”¶ç›Šï¼ˆå›ºå®šå›æŠ¥æœŸï¼‰
        expected_lifetime = 12  # é¢„æœŸç”Ÿå‘½å‘¨æœŸ(æœˆ)
        monthly_reward = float(action.reward) if action.reward is not None else 0.0
        future_income = monthly_reward * expected_lifetime
        
        # 3. NPV = æœªæ¥æ”¶ç›Š - æˆæœ¬
        npv = future_income - build_cost
        
        # 4. è¿›åº¦å¥–åŠ±
        progress_reward = len(self.buildings) * 0.5
        
        # 5. åä½œå¥–åŠ±ï¼ˆå¯é…ç½®ï¼‰
        cooperation_bonus = self._calculate_cooperation_reward(agent, action)
        
        # 6. Budgetæƒ©ç½šï¼ˆè½¯çº¦æŸï¼‰
        budget_penalty = self._calculate_budget_penalty(agent, action)
        
        # 7. æ€»å¥–åŠ± = NPV + è¿›åº¦ + åä½œ - æƒ©ç½š
        total_reward = npv + progress_reward + cooperation_bonus - budget_penalty
    else:
        # ç©ºåºåˆ—ï¼ˆä¸å»ºé€ ï¼‰ï¼šæ— reward
        total_reward = 0.0
    
    # 8. å¥–åŠ±ç¼©æ”¾
    scaled_reward = total_reward / reward_scale  # é»˜è®¤30000
    scaled_reward = np.clip(scaled_reward, -1.0, 1.0)
    
    return scaled_reward
```

### åä½œå¥–åŠ±æœºåˆ¶

```python
def _calculate_cooperation_reward(self, agent, action):
    cooperation_lambda = 0.2  # åä½œæƒé‡
    
    cooperation_bonus = 0.0
    
    # åŠŸèƒ½äº’è¡¥å¥–åŠ±
    if agent == 'EDU':
        cooperation_bonus += len(industrial_buildings) * 0.05
    elif agent == 'IND':
        cooperation_bonus += len(public_buildings) * 0.05
    
    # ç©ºé—´åè°ƒå¥–åŠ±
    for other_building in all_buildings:
        distance = calculate_distance(action, other_building)
        if 5 <= distance <= 20:
            cooperation_bonus += 0.02
    
    return cooperation_lambda * cooperation_bonus
```

### æœˆåº¦æ”¶ç›Šç´¯ç§¯æœºåˆ¶

```python
def _calculate_monthly_income(self, agent):
    """è®¡ç®—agentçš„æœˆåº¦æ”¶ç›Šï¼ˆæ‰€æœ‰åœ¨è¥å»ºç­‘çš„ç´¯åŠ ï¼‰"""
    total_income = sum([
        asset['monthly_income'] 
        for asset in self.active_assets[agent]
    ])
    return total_income

def _advance_turn(self):
    """æ¯æœˆå¼€å§‹æ—¶ï¼Œä¸ºæ‰€æœ‰agentç´¯åŠ æœˆåº¦æ”¶ç›Šåˆ°budget"""
    # ã€æœˆåº¦æ”¶ç›Šæœºåˆ¶ã€‘æ¯æœˆå¼€å§‹æ—¶ï¼Œä¸ºæ‰€æœ‰agentç´¯åŠ æœˆåº¦æ”¶ç›Šåˆ°budget
    if self.budgets is not None:
        for agent in self.rl_cfg['agents']:
            monthly_income = self._calculate_monthly_income(agent)
            self.budgets[agent] += monthly_income  # æ¯æœˆçœŸå®ç´¯ç§¯æ”¶ç›Š
            
            # è®°å½•æœˆåº¦æ”¶ç›Šå†å²
            self.monthly_income_history[agent].append(monthly_income)

def _place_building(self, agent, action):
    """æ”¾ç½®å»ºç­‘æ—¶è®°å½•ä¸ºåœ¨è¥èµ„äº§"""
    # ã€æœˆåº¦æ”¶ç›Šæœºåˆ¶ã€‘è®°å½•ä¸ºåœ¨è¥èµ„äº§
    asset = {
        'size': action.size,
        'monthly_income': float(action.reward),  # å­˜å‚¨æœˆåº¦æ”¶ç›Š
        'cost': float(action.cost),
        'built_month': self.current_month,
    }
    self.active_assets[agent].append(asset)  # æ·»åŠ åˆ°åœ¨è¥èµ„äº§åˆ—è¡¨
```

### åŒé‡æ”¶ç›Šæœºåˆ¶è¯¦è§£

ç³»ç»Ÿè®¾è®¡äº†**åŒé‡æ”¶ç›Šæœºåˆ¶**æ¥å¹³è¡¡RLè®­ç»ƒå’Œè´¢åŠ¡çº¦æŸï¼š

#### 1. **RLå¥–åŠ±å±‚é¢ï¼ˆNPVæœºåˆ¶ï¼‰**
```python
# RLçœ‹åˆ°çš„æ˜¯é•¿æœŸä»·å€¼
expected_lifetime = 12  # 12ä¸ªæœˆé¢„æœŸç”Ÿå‘½å‘¨æœŸ
future_income = monthly_reward * expected_lifetime
npv = future_income - build_cost

# ç¤ºä¾‹ï¼šIND Må‹å»ºç­‘
# npv = 283 * 12 - 2602 = 3396 - 2602 = 794 kGBP (æ­£æ”¶ç›Š)
```

**ä½œç”¨**ï¼šç»™RLæ™ºèƒ½ä½“æ­£ç¡®çš„"æŠ•èµ„å›æŠ¥"ä¿¡å·ï¼Œé¼“åŠ±é•¿æœŸæŠ•èµ„è¡Œä¸ºã€‚

#### 2. **Budgetç³»ç»Ÿå±‚é¢ï¼ˆç°é‡‘æµç®¡ç†ï¼‰**
```python
# æ¯æœˆçœŸå®ç´¯ç§¯æ”¶ç›Š
def _advance_turn(self):
    for agent in agents:
        monthly_income = sum([asset.monthly_income for asset in active_assets])
        budget[agent] += monthly_income

# ç¤ºä¾‹ï¼šIND Må‹å»ºç­‘çš„Budgetå˜åŒ–
# Month 0: budget = 15000 - 2602 = 12398  # å»ºé€ æˆæœ¬
# Month 1: budget = 12398 + 283 = 12681   # ç¬¬1ä¸ªæœˆæ”¶ç›Š
# Month 2: budget = 12681 + 283 = 12964   # ç¬¬2ä¸ªæœˆæ”¶ç›Š
# ...
# Month 12: budget = 15000 + 794 = 15794  # 12ä¸ªæœˆåå‡€æ”¶ç›Š794
```

**ä½œç”¨**ï¼šæä¾›çœŸå®çš„ç°é‡‘æµç®¡ç†ï¼Œé˜²æ­¢è¿‡åº¦å€Ÿè´·ï¼Œç¡®ä¿è´¢åŠ¡å¯æŒç»­æ€§ã€‚

#### 3. **ä¸¤è€…åè°ƒæ€§**
- **è®¾è®¡ä¸€è‡´æ€§**ï¼š12ä¸ªæœˆåBudgetå¢é•¿ä¸NPVè®¡ç®—å®Œå…¨ä¸€è‡´
- **åŠŸèƒ½äº’è¡¥**ï¼šRLè´Ÿè´£é•¿æœŸç­–ç•¥ï¼ŒBudgetè´Ÿè´£çŸ­æœŸçº¦æŸ
- **é¿å…çŸ›ç›¾**ï¼šä¸å­˜åœ¨"RLè¯´èµšé’±ä½†Budgetè¯´äºé’±"çš„æƒ…å†µ

---

## Budgetç³»ç»Ÿ

### é…ç½®å‚æ•°

```json
"budget_system": {
    "enabled": true,
    "mode": "soft_constraint",
    "initial_budgets": {
        "IND": 15000,  // å·¥ä¸šæ™ºèƒ½ä½“åˆå§‹é¢„ç®—
        "EDU": 10000   // æ•™è‚²æ™ºèƒ½ä½“åˆå§‹é¢„ç®—
    },
    "debt_penalty_coef": 0.1,        // è´Ÿå€ºæƒ©ç½šç³»æ•°
    "max_debt": -2000,               // æœ€å¤§å…è®¸è´Ÿå€º
    "bankruptcy_threshold": -5000,   // ç ´äº§é˜ˆå€¼
    "bankruptcy_penalty": -100.0     // ç ´äº§æƒ©ç½š
}
```

### Budgetæƒ©ç½šè®¡ç®—

```python
def _calculate_budget_penalty(self, agent, action):
    if self.budgets is None:
        return 0.0
    
    # é¢„ä¼°å»ºé€ åçš„budget
    budget_after = self.budgets[agent] - action.cost
    
    budget_penalty = 0.0
    
    # è´Ÿå€ºæƒ©ç½š
    if budget_after < 0:
        debt_penalty_coef = 0.1
        budget_penalty = abs(budget_after) * debt_penalty_coef
    
    # ç ´äº§æƒ©ç½š
    if budget_after < -5000:
        budget_penalty += 100.0
    
    return budget_penalty
```

### Budgetæ›´æ–°æœºåˆ¶

```python
def step(self, action):
    # 1. å»ºé€ æ—¶æ‰£é™¤æˆæœ¬
    if action.build:
        self.budgets[agent] -= action.cost
    
    # 2. æ¯æœˆç´¯åŠ æœˆåº¦æ”¶ç›Š
    monthly_income = self._calculate_monthly_income(agent)
    self.budgets[agent] += monthly_income
    
    # 3. è®°å½•budgetå†å²
    self.budget_history[agent].append(self.budgets[agent])
```

---

## åŠ¨ä½œé€‰æ‹©ä¸è¯„åˆ†

### ActionScorerè¯„åˆ†æœºåˆ¶

```python
def score_actions(self, actions):
    # 1. è®¡ç®—åŸå§‹cost/reward/prestige
    for action in actions:
        self._calc_crp(action)
    
    # 2. å½’ä¸€åŒ–å„ç»´åº¦
    costs = [a.cost for a in actions]
    rewards = [a.reward for a in actions]
    prestiges = [a.prestige for a in actions]
    
    c_min, c_max = min(costs), max(costs)
    r_min, r_max = min(rewards), max(rewards)
    p_min, p_max = min(prestiges), max(prestiges)
    
    def norm(v, lo, hi):
        return (v - lo) / (hi - lo) if hi - lo > 1e-9 else 0.5
    
    # 3. æŒ‰æ™ºèƒ½ä½“ä½¿ç”¨ä¸åŒæƒé‡è®¡ç®—ç»¼åˆè¯„åˆ†
    for action in actions:
        w = self.objective.get(action.agent, {"w_r": 0.5, "w_p": 0.3, "w_c": 0.2})
        
        nr = norm(action.reward, r_min, r_max)
        np = norm(action.prestige, p_min, p_max)
        nc = norm(action.cost, c_min, c_max)
        
        action.score = w["w_r"] * nr + w["w_p"] * np - w["w_c"] * nc
    
    return actions
```

### æ™ºèƒ½ä½“æƒé‡é…ç½®

```json
"objective": {
    "EDU": {
        "w_r": 0.45,  // rewardæƒé‡
        "w_p": 0.45,  // prestigeæƒé‡  
        "w_c": 0.1    // costæƒé‡
    },
    "IND": {
        "w_r": 0.6,   // rewardæƒé‡
        "w_p": 0.2,   // prestigeæƒé‡
        "w_c": 0.2    // costæƒé‡
    }
}
```

### åŠ¨ä½œé€‰æ‹©ç­–ç•¥

1. **æšä¸¾é˜¶æ®µ**: ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„å»ºç­‘åŠ¨ä½œ
2. **è¯„åˆ†é˜¶æ®µ**: ä½¿ç”¨ActionScorerè®¡ç®—ç»¼åˆè¯„åˆ†
3. **æ’åºé˜¶æ®µ**: æŒ‰è¯„åˆ†é™åºæ’åˆ—
4. **é€‰æ‹©é˜¶æ®µ**: RLæ™ºèƒ½ä½“ä»æ’åºåçš„åŠ¨ä½œä¸­é€‰æ‹©

---

## é…ç½®å‚æ•°è¯¦è§£

### æ ¸å¿ƒé…ç½®ç»“æ„

```json
{
    "simulation": {
        "total_months": 30
    },
    "city": {
        "map_size": [200, 200],
        "transport_hubs": [[122, 80], [112, 121]]
    },
    "budget_system": {
        "enabled": true,
        "initial_budgets": {"IND": 15000, "EDU": 10000},
        "debt_penalty_coef": 0.1,
        "bankruptcy_threshold": -5000
    },
    "growth_v4_1": {
        "enumeration": {
            "objective": {
                "EDU": {"w_r": 0.45, "w_p": 0.45, "w_c": 0.1},
                "IND": {"w_r": 0.6, "w_p": 0.2, "w_c": 0.2}
            }
        },
        "evaluation": {
            "BaseCost_IND": {"S": 900, "M": 1500, "L": 2400},
            "BaseCost_EDU": {"S": 700, "M": 1200, "L": 1900},
            "RevBase_IND": {"S": 180, "M": 320, "L": 520},
            "RevBase_EDU": {"S": 140, "M": 260, "L": 420},
            "LandPriceBase": 11.0,
            "RiverPmax_pct": {"IND": 20, "EDU": 15},
            "RiverD_half_m": 120,
            "size_bonus": {"M": 1000, "L": 2000}
        }
    },
    "solver": {
        "rl": {
            "reward_scale": 30000.0,
            "reward_clip": 1.0,
            "cooperation_lambda": 0.0
        }
    }
}
```

---

## è®¡ç®—æµç¨‹ç¤ºä¾‹

### å®Œæ•´è®¡ç®—ç¤ºä¾‹

å‡è®¾è¦åœ¨ä½ç½®(100, 80)å»ºé€ ä¸€ä¸ªIND Må‹å»ºç­‘:

#### 1. è¾“å…¥å‚æ•°
- agent: "IND"
- size: "M"
- zone: "near" (è·ç¦»hub1 < 15å•ä½)
- LP_norm: 0.8 (åœ°ä»·å½’ä¸€åŒ–å€¼)
- adj: 1 (æœ‰é‚»æ¥å»ºç­‘)
- river_dist_m: 30 (è·ç¦»æ²³æµ30ç±³)

#### 2. Costè®¡ç®—
```
LP_idx = 10 + (100-10) * 0.8 = 82
LP_value = 82 * 11 = 902 kGBP
cost = 1500 + 200 + 902 = 2602 kGBP
```

#### 3. Rewardè®¡ç®—
```
reward_base = 320 + 80 + 0 - 180 - 45 + 61 = 236
reward = 236 * (1 + 0.25 * 0.8) = 283 kGBP/æœˆ
```

#### 4. Prestigeè®¡ç®—
```
prestige = 0.1 + 1.0 + 1.0 - 0.2 * 0.9 = 1.82
```

#### 5. ActionScorerè¯„åˆ†
```
# å‡è®¾å½“å‰æ‰¹æ¬¡ä¸­:
# costs: [1000, 2000, 2602, 3000]
# rewards: [100, 200, 283, 400]  
# prestiges: [0.5, 1.0, 1.82, 2.0]

nr = (283-100)/(400-100) = 0.61
np = (1.82-0.5)/(2.0-0.5) = 0.88
nc = (2602-1000)/(3000-1000) = 0.80

score = 0.6 * 0.61 + 0.2 * 0.88 - 0.2 * 0.80 = 0.47
```

#### 6. RLå¥–åŠ±è®¡ç®—
```
# NPVè®¡ç®— (12ä¸ªæœˆé¢„æœŸæ”¶ç›Š)
future_income = 283 * 12 = 3396 kGBP
npv = 3396 - 2602 = 794 kGBP

progress_reward = 5 * 0.5 = 2.5
cooperation_bonus = 0 (é»˜è®¤ç¦ç”¨)
budget_penalty = 0 (å‡è®¾budgetå……è¶³)

total_reward = 794 + 2.5 + 0 - 0 = 796.5
scaled_reward = 796.5 / 30000 = 0.027
```

#### 7. Budgetæ›´æ–°
```
# å»ºé€ æ—¶
budget_IND = 15000 - 2602 = 12398

# æ¯æœˆæ”¶ç›Š
budget_IND = 12398 + 283 = 12681
```

---

## æ€»ç»“

### ç³»ç»Ÿç‰¹ç‚¹
1. **åŒå±‚æ¶æ„**: ActionScorerè´Ÿè´£ç»æµè®¡ç®—ï¼ŒEnvironmentè´Ÿè´£RLå¥–åŠ±è½¬æ¢
2. **å¤šç»´åº¦è¯„ä¼°**: ç»¼åˆè€ƒè™‘costã€rewardã€prestigeä¸‰ä¸ªç»´åº¦
3. **æ™ºèƒ½ä½“å·®å¼‚åŒ–**: EDUé‡è§†prestigeï¼ŒINDé‡è§†reward
4. **åŒé‡æ”¶ç›Šæœºåˆ¶**: RLä½¿ç”¨NPVè€ƒè™‘é•¿æœŸä»·å€¼ï¼ŒBudgetç³»ç»Ÿç®¡ç†çœŸå®ç°é‡‘æµ
5. **æœˆåº¦æ”¶ç›Šæœºåˆ¶**: å»ºç­‘å»ºæˆåæŒç»­äº§ç”Ÿæ”¶ç›Šï¼Œæ¯æœˆçœŸå®ç´¯ç§¯åˆ°Budget
6. **è½¯çº¦æŸBudget**: å…è®¸é€‚åº¦è´Ÿå€ºï¼Œé¿å…è¿‡åº¦ä¿å®ˆ

### å…³é”®è®¾è®¡ç†å¿µ
- **ç»æµåˆç†æ€§**: æˆæœ¬æ”¶ç›Šè®¡ç®—åŸºäºçœŸå®ç»æµé€»è¾‘
- **å¯æŒç»­æ€§**: æœˆåº¦æ”¶ç›Šç¡®ä¿é•¿æœŸç›ˆåˆ©
- **åä½œæ€§**: å¤šæ™ºèƒ½ä½“é—´çš„åŠŸèƒ½äº’è¡¥å’Œç©ºé—´åè°ƒ
- **å¯é…ç½®æ€§**: ä¸°å¯Œçš„å‚æ•°é…ç½®æ”¯æŒä¸åŒåœºæ™¯

### ç³»ç»Ÿä¼˜åŠ¿
1. **åŒé‡æ”¶ç›Šæœºåˆ¶**: RLä½¿ç”¨NPVè€ƒè™‘é•¿æœŸä»·å€¼ï¼ŒBudgetç³»ç»Ÿç®¡ç†çœŸå®ç°é‡‘æµ
2. **åˆç†çš„ç»æµé€»è¾‘**: 12ä¸ªæœˆé¢„æœŸç”Ÿå‘½å‘¨æœŸä¸æœˆåº¦æ”¶ç›Šç´¯ç§¯æœºåˆ¶åè°ƒä¸€è‡´
3. **æ™ºèƒ½ä½“å·®å¼‚åŒ–**: EDUé‡è§†prestigeï¼ŒINDé‡è§†rewardï¼Œä½“ç°ä¸åŒè§’è‰²å®šä½
4. **è½¯çº¦æŸBudget**: å…è®¸é€‚åº¦è´Ÿå€ºï¼Œé¿å…è¿‡åº¦ä¿å®ˆï¼ŒåŒæ—¶é˜²æ­¢ç ´äº§

### å½“å‰å¯èƒ½çš„é—®é¢˜
1. **å‚æ•°è°ƒä¼˜**: expected_lifetimeã€reward_scaleç­‰å‚æ•°å¯èƒ½éœ€è¦æ ¹æ®å®é™…è®­ç»ƒæ•ˆæœè°ƒæ•´
2. **åä½œæœºåˆ¶è¾ƒå¼±**: cooperation_lambda=0.0é»˜è®¤ç¦ç”¨ï¼Œå¤šæ™ºèƒ½ä½“åä½œä¿¡å·å¾®å¼±
3. **è®­ç»ƒè¶…å‚æ•°**: å­¦ä¹ ç‡ã€clip_epsç­‰å¯èƒ½éœ€è¦é’ˆå¯¹å…·ä½“åœºæ™¯ä¼˜åŒ–

### ç³»ç»Ÿè®¾è®¡åˆç†æ€§
- **RLå¥–åŠ±æœºåˆ¶**: ä½¿ç”¨NPVç»™RLæ­£ç¡®çš„"æŠ•èµ„å›æŠ¥"ä¿¡å·ï¼Œé¼“åŠ±é•¿æœŸæŠ•èµ„
- **Budgetç³»ç»Ÿ**: æ¯æœˆçœŸå®ç´¯ç§¯æ”¶ç›Šï¼Œæä¾›è´¢åŠ¡çº¦æŸï¼Œé˜²æ­¢è¿‡åº¦å€Ÿè´·
- **ä¸¤è€…åè°ƒ**: 12ä¸ªæœˆåBudgetå¢é•¿ä¸NPVè®¡ç®—ä¸€è‡´ï¼Œè®¾è®¡åˆç†

è¿™ä¸ªç³»ç»Ÿä¸ºåŸå¸‚è§„åˆ’å’Œå¤šæ™ºèƒ½ä½“å†³ç­–æä¾›äº†ä¸€ä¸ªå®Œæ•´çš„è®¡ç®—æ¡†æ¶ï¼Œé€šè¿‡ç²¾ç»†çš„ç»æµå»ºæ¨¡å’Œå¥–åŠ±è®¾è®¡æ¥æŒ‡å¯¼æ™ºèƒ½ä½“çš„å†³ç­–è¡Œä¸ºã€‚æ ¸å¿ƒé€»è¾‘è®¾è®¡åˆç†ï¼Œé—®é¢˜ä¸»è¦åœ¨äºå‚æ•°è°ƒä¼˜å’Œè®­ç»ƒé…ç½®ã€‚
